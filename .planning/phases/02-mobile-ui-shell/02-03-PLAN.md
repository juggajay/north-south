---
phase: 02-mobile-ui-shell
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - convex/schema.ts
  - convex/chat.ts
  - src/lib/gemini.ts
autonomous: true

user_setup:
  - service: google-gemini
    why: "AI chat for product knowledge"
    env_vars:
      - name: GEMINI_API_KEY
        source: "Google AI Studio (https://aistudio.google.com/apikey) -> Create API key"

must_haves:
  truths:
    - "Chat messages persist in Convex database"
    - "Gemini responds with product knowledge when asked about materials"
    - "Gemini refuses off-topic questions with boundary message"
    - "Conversation history maintained across messages"
  artifacts:
    - path: "convex/schema.ts"
      provides: "Chat tables (conversations, messages)"
      contains: "conversations"
    - path: "convex/chat.ts"
      provides: "Chat mutations and Gemini action"
      exports: ["sendMessage", "getConversation", "listConversations"]
    - path: "src/lib/gemini.ts"
      provides: "Gemini system prompt and configuration"
      exports: ["SYSTEM_INSTRUCTION"]
  key_links:
    - from: "convex/chat.ts"
      to: "@google/genai"
      via: "action with API call"
      pattern: "GoogleGenAI"
    - from: "convex/chat.ts"
      to: "convex/schema.ts"
      via: "ctx.db mutations"
      pattern: "ctx\\.db\\.(insert|get|query)"
---

<objective>
Implement chat backend with Convex storage and Gemini 3.0 Flash integration for product knowledge Q&A.

Purpose: Enable the AI chat feature that helps customers learn about materials, hardware, and joinery options with a friendly tradesperson personality.

Output: Convex schema for conversations/messages, chat mutations, and Gemini action with strict product-knowledge boundaries.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-mobile-ui-shell/02-CONTEXT.md
@.planning/phases/02-mobile-ui-shell/02-RESEARCH.md
@convex/schema.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add chat tables to Convex schema</name>
  <files>convex/schema.ts</files>
  <action>
    Add two new tables to schema.ts for chat functionality:

    conversations table:
    ```typescript
    conversations: defineTable({
      userId: v.optional(v.id("users")), // Optional for anonymous users
      title: v.optional(v.string()),     // Auto-generated from first message
      lastMessageAt: v.number(),         // Unix timestamp for sorting
      unreadCount: v.number(),           // Track unread for badge
      createdAt: v.number(),
    })
      .index("by_userId", ["userId"])
      .index("by_lastMessageAt", ["lastMessageAt"]),
    ```

    messages table:
    ```typescript
    messages: defineTable({
      conversationId: v.id("conversations"),
      role: v.string(),                  // "user" | "assistant"
      content: v.string(),
      createdAt: v.number(),
    })
      .index("by_conversationId", ["conversationId"])
      .index("by_createdAt", ["createdAt"]),
    ```

    Place these after the existing notifications table, before product catalog section.
    Keep all existing tables unchanged.
  </action>
  <verify>
    - `npx convex dev` runs without schema errors
    - conversations and messages tables visible in Convex dashboard
  </verify>
  <done>
    Convex schema includes conversations and messages tables with proper indexes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Gemini system prompt configuration</name>
  <files>src/lib/gemini.ts</files>
  <action>
    Create src/lib/gemini.ts with the system instruction from CONTEXT.md:

    ```typescript
    export const SYSTEM_INSTRUCTION = `You are a knowledgeable tradesperson who specializes in custom cabinetry and joinery. You work for North South Carpentry.

    Your expertise covers:
    - Materials (Polytec finishes, timber veneers, laminates)
    - Hardware (Blum hinges, drawer systems, soft-close mechanisms)
    - Pricing questions about cabinetry components
    - Joinery options and construction methods

    Your personality:
    - Friendly expert who genuinely knows and loves materials
    - Use phrases like "That Polytec finish is great for kitchens, handles moisture well"
    - Practical, helpful, no unnecessary jargon

    STRICT BOUNDARY: You can ONLY discuss joinery, materials, hardware, and cabinetry.
    For ANY off-topic question, respond EXACTLY: "I can only help with joinery and materials. What would you like to know about your project?"
    Do not engage with politics, general knowledge, or topics outside cabinetry.`;

    export const GEMINI_CONFIG = {
      model: "gemini-2.0-flash",
      temperature: 1.0, // Google recommends keeping at 1.0
    };
    ```

    Note: Using gemini-2.0-flash as it's the current stable version. The research mentioned "gemini-3-flash-preview" but this may not be available yet - use gemini-2.0-flash which is the production-ready fast model.
  </action>
  <verify>
    - src/lib/gemini.ts exists
    - SYSTEM_INSTRUCTION includes all personality traits from CONTEXT.md
    - Strict boundary message matches exactly
  </verify>
  <done>
    Gemini configuration file with tradesperson personality and strict product-knowledge boundaries.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create chat Convex mutations and Gemini action</name>
  <files>convex/chat.ts</files>
  <action>
    Create convex/chat.ts with:

    1. Install @google/genai:
    ```bash
    npm install @google/genai
    ```

    2. Queries:
    - `getConversation`: Get conversation by ID with messages
    - `listConversations`: List user's conversations sorted by lastMessageAt
    - `getUnreadCount`: Get total unread messages for badge

    3. Mutations:
    - `createConversation`: Create new conversation
    - `markAsRead`: Reset unreadCount to 0

    4. Action (for Gemini API call):
    - `sendMessage`: Main action that:
      a. Gets or creates conversation
      b. Stores user message
      c. Fetches conversation history (last 20 messages for context)
      d. Calls Gemini API with system instruction + history
      e. Stores assistant response
      f. Updates conversation lastMessageAt and unreadCount
      g. Returns assistant response

    Implementation pattern from RESEARCH.md:
    ```typescript
    import { GoogleGenAI } from "@google/genai";
    import { action, mutation, query, internalMutation, internalQuery } from "./_generated/server";
    import { v } from "convex/values";
    import { SYSTEM_INSTRUCTION, GEMINI_CONFIG } from "../src/lib/gemini";

    // Internal queries/mutations for action to call
    export const internal_getHistory = internalQuery({...});
    export const internal_storeMessage = internalMutation({...});

    export const sendMessage = action({
      args: {
        conversationId: v.optional(v.id("conversations")),
        message: v.string(),
        userId: v.optional(v.id("users")),
      },
      handler: async (ctx, args) => {
        const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });

        // Get history if existing conversation
        const history = args.conversationId
          ? await ctx.runQuery(internal.chat.internal_getHistory, {
              conversationId: args.conversationId,
            })
          : [];

        // Format history for Gemini
        const formattedHistory = history.map((msg) => ({
          role: msg.role as "user" | "model",
          parts: [{ text: msg.content }],
        }));

        // Create chat session
        const chat = ai.chats.create({
          model: GEMINI_CONFIG.model,
          config: {
            systemInstruction: SYSTEM_INSTRUCTION,
            temperature: GEMINI_CONFIG.temperature,
          },
          history: formattedHistory,
        });

        // Send message
        const response = await chat.sendMessage({ message: args.message });
        const assistantMessage = response.text;

        // Store both messages
        const conversationId = await ctx.runMutation(internal.chat.internal_storeMessages, {
          conversationId: args.conversationId,
          userId: args.userId,
          userMessage: args.message,
          assistantMessage,
        });

        return {
          conversationId,
          response: assistantMessage,
        };
      },
    });
    ```

    Handle errors gracefully - if Gemini fails, return a friendly error message.
  </action>
  <verify>
    - `npm install @google/genai` succeeds
    - `npx convex dev` runs without errors
    - All exports visible in Convex functions list
    - Test via Convex dashboard: run sendMessage action with test message about materials
  </verify>
  <done>
    Chat backend complete with Convex persistence and Gemini integration. Messages stored, history maintained, responses follow product-knowledge personality.
  </done>
</task>

</tasks>

<verification>
- Convex schema includes conversations and messages tables
- @google/genai installed in package.json
- src/lib/gemini.ts exports SYSTEM_INSTRUCTION
- convex/chat.ts exports sendMessage action, queries, mutations
- `npx convex dev` runs without errors
- Manual test: sendMessage with "What materials do you recommend?" returns tradesperson-style response
- Manual test: sendMessage with "What's the weather?" returns boundary message
</verification>

<success_criteria>
- Chat tables in Convex schema with proper indexes
- Gemini integration working with product knowledge boundaries
- Conversation history persists across messages
- Error handling for API failures
- Ready for frontend integration in Plan 05
</success_criteria>

<output>
After completion, create `.planning/phases/02-mobile-ui-shell/02-03-SUMMARY.md`
</output>
