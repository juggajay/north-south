---
phase: 03-ai-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/lib/ai/claude-vision.ts
  - convex/ai.ts
autonomous: true
user_setup:
  - service: anthropic
    why: "Claude Vision API for space analysis"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console -> API Keys -> Create Key"

must_haves:
  truths:
    - "Photos can be analyzed for room features and style"
    - "Space analysis returns structured JSON with dimensions and features"
    - "Invalid images return helpful error messages"
  artifacts:
    - path: "src/lib/ai/claude-vision.ts"
      provides: "Claude Vision API client"
      exports: ["analyzeSpace", "imageUriToBase64"]
    - path: "convex/ai.ts"
      provides: "Server-side AI action"
      exports: ["analyzeSpaceAction"]
  key_links:
    - from: "src/lib/ai/claude-vision.ts"
      to: "process.env.ANTHROPIC_API_KEY"
      via: "environment variable"
      pattern: "ANTHROPIC_API_KEY"
    - from: "convex/ai.ts"
      to: "@anthropic-ai/sdk"
      via: "SDK import"
      pattern: "import Anthropic"
---

<objective>
Implement Claude Vision integration for analyzing user photos to extract room features, dimensions, and style aesthetic.

Purpose: First stage of AI pipeline - understanding what's in the user's photo before generating renders.
Output: Server-side action that returns structured SpaceAnalysis from any cabinet space photo.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-ai-pipeline/03-RESEARCH.md
@.planning/phases/03-ai-pipeline/03-01-SUMMARY.md
@src/types/ai-pipeline.ts
@src/lib/image-quality.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Anthropic SDK</name>
  <files>package.json</files>
  <action>
Install the official Anthropic TypeScript SDK:

```bash
npm install @anthropic-ai/sdk
```

This provides the typed Claude API client for Vision requests.
  </action>
  <verify>`npm list @anthropic-ai/sdk` shows installed version</verify>
  <done>Anthropic SDK installed and available for import</done>
</task>

<task type="auto">
  <name>Task 2: Create Claude Vision Client</name>
  <files>src/lib/ai/claude-vision.ts</files>
  <action>
Create the Claude Vision integration following RESEARCH.md patterns:

```typescript
import Anthropic from '@anthropic-ai/sdk';
import { SpaceAnalysis } from '@/types/ai-pipeline';
import { z } from 'zod';

// Zod schema for validating Claude's response
const SpaceAnalysisSchema = z.object({
  roomType: z.string(),
  estimatedWidth: z.number(),
  estimatedDepth: z.number(),
  estimatedHeight: z.number(),
  features: z.array(z.string()),
  styleAesthetic: z.enum(['modern', 'traditional', 'industrial', 'coastal', 'scandinavian']),
  lightingConditions: z.enum(['natural', 'artificial', 'mixed']),
  flooring: z.string(),
  wallFinishes: z.string(),
});

/**
 * Convert image URI (from Capacitor) to base64 for Claude Vision API
 * Handles data URLs and file URIs
 */
export async function imageUriToBase64(uri: string): Promise<string> {
  // If already base64 data URL, extract the base64 part
  if (uri.startsWith('data:')) {
    return uri.split(',')[1];
  }

  // Fetch the image and convert to base64
  const response = await fetch(uri);
  const blob = await response.blob();

  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      const dataUrl = reader.result as string;
      resolve(dataUrl.split(',')[1]);
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
}

/**
 * Resize image to max 1568px on longest edge (Claude Vision optimal size)
 * Larger images get auto-resized by Claude, adding latency without quality gain
 */
export async function resizeImageForVision(base64: string): Promise<string> {
  return new Promise((resolve) => {
    const img = new Image();
    img.onload = () => {
      const maxDim = 1568;
      let { width, height } = img;

      if (width <= maxDim && height <= maxDim) {
        resolve(base64);
        return;
      }

      // Scale down maintaining aspect ratio
      if (width > height) {
        height = (height * maxDim) / width;
        width = maxDim;
      } else {
        width = (width * maxDim) / height;
        height = maxDim;
      }

      const canvas = document.createElement('canvas');
      canvas.width = width;
      canvas.height = height;
      const ctx = canvas.getContext('2d')!;
      ctx.drawImage(img, 0, 0, width, height);

      // Return base64 without data URL prefix
      resolve(canvas.toDataURL('image/jpeg', 0.9).split(',')[1]);
    };
    img.src = `data:image/jpeg;base64,${base64}`;
  });
}

/**
 * Analyze space using Claude Vision API
 * Returns structured analysis of room features, dimensions, and style
 */
export async function analyzeSpace(
  imageBase64: string,
  apiKey: string
): Promise<SpaceAnalysis> {
  const client = new Anthropic({ apiKey });

  // Ensure image is optimally sized
  const resizedImage = await resizeImageForVision(imageBase64);

  const message = await client.messages.create({
    model: 'claude-sonnet-4-5-20250514',
    max_tokens: 1024,
    messages: [
      {
        role: 'user',
        content: [
          {
            type: 'image',
            source: {
              type: 'base64',
              media_type: 'image/jpeg',
              data: resizedImage,
            },
          },
          {
            type: 'text',
            text: `Analyze this space for joinery/cabinetry installation. You are helping a custom joinery company understand this room.

Extract and return ONLY a JSON object with these exact fields:
{
  "roomType": "kitchen/bedroom/living/office/laundry/garage/other",
  "estimatedWidth": <width in millimeters, estimate based on typical room proportions>,
  "estimatedDepth": <depth in millimeters>,
  "estimatedHeight": <ceiling height in millimeters, typically 2400-2700mm>,
  "features": ["list", "of", "features like windows, doors, alcoves, power points"],
  "styleAesthetic": "modern/traditional/industrial/coastal/scandinavian",
  "lightingConditions": "natural/artificial/mixed",
  "flooring": "description of floor type and color",
  "wallFinishes": "description of wall color/texture"
}

For dimensions:
- Standard Australian ceiling height is 2400mm
- Use reference objects (doors ~2100mm, switches ~1200mm from floor) to estimate
- If uncertain, provide reasonable estimates for the room type

Return ONLY the JSON object, no markdown formatting or explanation.`,
          },
        ],
      },
    ],
  });

  // Extract text content from response
  const textContent = message.content.find((block) => block.type === 'text');
  if (!textContent || textContent.type !== 'text') {
    throw new Error('No text response from Claude Vision');
  }

  // Parse and validate with Zod
  try {
    // Handle potential markdown code blocks
    let jsonStr = textContent.text.trim();
    if (jsonStr.startsWith('```')) {
      jsonStr = jsonStr.replace(/```json?\n?/g, '').replace(/```/g, '').trim();
    }

    const parsed = JSON.parse(jsonStr);
    return SpaceAnalysisSchema.parse(parsed);
  } catch (error) {
    console.error('Failed to parse Claude response:', textContent.text);
    throw new Error('Invalid response format from Claude Vision. Please try again.');
  }
}
```

Key implementation notes:
- Uses claude-sonnet-4-5 model (cost-effective for vision)
- Resizes images to 1568px max to avoid latency penalty
- Validates response with Zod schema
- Handles markdown code block wrapping in response
- Dimensions in mm (Australian standard)
  </action>
  <verify>`npm run typecheck` passes, function exported</verify>
  <done>Claude Vision client with space analysis capability</done>
</task>

<task type="auto">
  <name>Task 3: Create Convex AI Action</name>
  <files>convex/ai.ts</files>
  <action>
Create a Convex action to run Claude Vision server-side (keeps API key secure):

```typescript
import { action } from './_generated/server';
import { v } from 'convex/values';
import Anthropic from '@anthropic-ai/sdk';
import { z } from 'zod';

// Zod schema for validating Claude's response
const SpaceAnalysisSchema = z.object({
  roomType: z.string(),
  estimatedWidth: z.number(),
  estimatedDepth: z.number(),
  estimatedHeight: z.number(),
  features: z.array(z.string()),
  styleAesthetic: z.enum(['modern', 'traditional', 'industrial', 'coastal', 'scandinavian']),
  lightingConditions: z.enum(['natural', 'artificial', 'mixed']),
  flooring: z.string(),
  wallFinishes: z.string(),
});

export const analyzeSpaceAction = action({
  args: {
    imageBase64: v.string(),
  },
  handler: async (ctx, args) => {
    const apiKey = process.env.ANTHROPIC_API_KEY;
    if (!apiKey) {
      throw new Error('ANTHROPIC_API_KEY not configured');
    }

    const client = new Anthropic({ apiKey });

    const message = await client.messages.create({
      model: 'claude-sonnet-4-5-20250514',
      max_tokens: 1024,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image',
              source: {
                type: 'base64',
                media_type: 'image/jpeg',
                data: args.imageBase64,
              },
            },
            {
              type: 'text',
              text: `Analyze this space for joinery/cabinetry installation. You are helping a custom joinery company understand this room.

Extract and return ONLY a JSON object with these exact fields:
{
  "roomType": "kitchen/bedroom/living/office/laundry/garage/other",
  "estimatedWidth": <width in millimeters>,
  "estimatedDepth": <depth in millimeters>,
  "estimatedHeight": <ceiling height in millimeters, typically 2400-2700mm>,
  "features": ["list", "of", "features"],
  "styleAesthetic": "modern/traditional/industrial/coastal/scandinavian",
  "lightingConditions": "natural/artificial/mixed",
  "flooring": "description of floor type",
  "wallFinishes": "description of wall finish"
}

Return ONLY the JSON object, no markdown formatting.`,
            },
          ],
        },
      ],
    });

    // Extract text content
    const textContent = message.content.find((block) => block.type === 'text');
    if (!textContent || textContent.type !== 'text') {
      throw new Error('No text response from Claude Vision');
    }

    // Parse and validate
    try {
      let jsonStr = textContent.text.trim();
      if (jsonStr.startsWith('```')) {
        jsonStr = jsonStr.replace(/```json?\n?/g, '').replace(/```/g, '').trim();
      }

      const parsed = JSON.parse(jsonStr);
      const validated = SpaceAnalysisSchema.parse(parsed);

      return {
        success: true,
        analysis: validated,
      };
    } catch (error) {
      console.error('Failed to parse Claude response:', textContent.text);
      return {
        success: false,
        error: 'Could not analyze the space. Please try a clearer photo.',
      };
    }
  },
});
```

Add ANTHROPIC_API_KEY to Convex environment variables:
- In Convex dashboard: Settings -> Environment Variables
- Or via CLI: `npx convex env set ANTHROPIC_API_KEY your-key-here`

Note: The client-side helper functions (imageUriToBase64, resizeImageForVision) remain in src/lib/ai/ for pre-processing before calling the Convex action.
  </action>
  <verify>`npm run typecheck` passes, action exported in convex/ai.ts</verify>
  <done>Server-side Convex action for secure Claude Vision calls</done>
</task>

</tasks>

<verification>
- [ ] `npm run typecheck` passes
- [ ] @anthropic-ai/sdk installed
- [ ] src/lib/ai/claude-vision.ts exports analyzeSpace, imageUriToBase64
- [ ] convex/ai.ts exports analyzeSpaceAction
- [ ] Zod validation catches malformed responses
</verification>

<success_criteria>
- Claude Vision client can analyze room photos
- Response validated with Zod schema
- Images resized to optimal 1568px before API call
- Convex action keeps API key server-side
- Error handling returns user-friendly messages
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-pipeline/03-02-SUMMARY.md`
</output>
